{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define content (import from scrapy script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file:\n",
    "data = json.load(open(\"pages_content.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare content \n",
    "\n",
    "#Gets a list of just the content from (urls against content)\n",
    "def strip_url_from_content(content):\n",
    "    return pd.DataFrame(content.items())[1].tolist()\n",
    "\n",
    "def url_against_page_no(content):\n",
    "    all_urls_page_num = {\n",
    "    'page_number': list(range(1, len(content)+1, 1)),\n",
    "    'url': pd.DataFrame(content.items())[0].tolist()\n",
    "    }\n",
    "    return pd.DataFrame(all_urls_page_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting out content:\n",
    "#Split content into each page (all content per page):\n",
    "\n",
    "def split_by_whole_page(content):\n",
    "    content = strip_url_from_content(content)\n",
    "    page_content = pd.DataFrame([content, list(range(1, len(content)+1))]).T\n",
    "    page_content.columns = ['phrase', 'page_number']\n",
    "    return page_content\n",
    "                         \n",
    "\n",
    "#Split content into sentences per page:\n",
    "def split_by_sentence(content):\n",
    "    all_phrases = []\n",
    "    for page_num, (url, content) in enumerate(content.items(), start=1):\n",
    "        content = content.split(\". \")\n",
    "        for phrase in content:\n",
    "            all_phrases.append((phrase, page_num))\n",
    "    df_phrases = pd.DataFrame(all_phrases, columns = ['phrase', 'page_number'])\n",
    "    return df_phrases\n",
    "\n",
    "#Split content into sentences per page:\n",
    "def split_by_sentence_1(content):\n",
    "    all_phrases = [\n",
    "        (phrase, page_num)\n",
    "        for content, page_num in enumerate(content, start=1)\n",
    "        for phrase in content.split(\". \")\n",
    "    ]\n",
    "    df_phrases = pd.DataFrame(all_phrases, columns = ['phrase', 'page_number'])\n",
    "    return df_phrases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classification (in, not in, exclusion):\n",
    "\n",
    "#Terms present:\n",
    "def find_terms_in(terms_list, df_o, terms_list_name):\n",
    "    df = df_o.copy()\n",
    "    phrases = df['phrase'].tolist()\n",
    "    all_terms = []\n",
    "    for phrase in phrases:\n",
    "        terms_per_phrase = []\n",
    "        for term in terms_list:\n",
    "            if term in phrase:\n",
    "                present = term\n",
    "            else: \n",
    "                present = 'NaN'\n",
    "            terms_per_phrase.append(present)\n",
    "        all_terms.append(terms_per_phrase)\n",
    "    all_terms = pd.DataFrame(all_terms)\n",
    "    df[terms_list_name]=all_terms.apply(lambda row: ', '.join(row.values.astype(str)), axis = 1)\n",
    "    df[terms_list_name] = df[terms_list_name].str.replace('NaN, ', '').str.replace(', NaN', '').str.replace('NaN', '')\n",
    "    return df\n",
    "\n",
    "#Find terms not present:\n",
    "def find_terms_notin(terms_list, df_o, terms_list_name):\n",
    "    df = df_o.copy()\n",
    "    phrases = df['phrase'].tolist()\n",
    "    all_terms = []\n",
    "    for phrase in phrases:\n",
    "        terms_per_phrase = []\n",
    "        for term in terms_list:\n",
    "            if term not in phrase:\n",
    "                present = term\n",
    "            else: \n",
    "                present = 'NaN'\n",
    "            terms_per_phrase.append(present)\n",
    "        all_terms.append(terms_per_phrase)\n",
    "    all_terms = pd.DataFrame(all_terms)\n",
    "    df[terms_list_name]=all_terms.apply(lambda row: ', '.join(row.values.astype(str)), axis = 1)\n",
    "    df[terms_list_name] = df[terms_list_name].str.replace('NaN, ', '').str.replace(', NaN', '').str.replace('NaN', '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For in-page, find sentences around the trigger word/s:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start defining content, terms lists, and rules here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define mock content\n",
    "\n",
    "content_1 = {\n",
    "    'url1': \"banana ice cream sale.\", #Page 1\n",
    "    'url2': \"chocolate ganache\", #Page 2\n",
    "    'url3': \"While strawberry is out of stock, try raspberry instead because you might just love it. This is a disclaimer.\", #Page 3\n",
    "    'url4': \"Cake range #1. Come try our desserts. You're guaranteed to love them. This is a disclaimer.\", #Page 4\n",
    "    'url5': \"Cake range #2. Come try our best value desserts. You're guaranteed to love them.\", #Page 5\n",
    "    }\n",
    "\n",
    "\n",
    "content_2 = {\n",
    "    'url1': \"banana ice cream\", #Page 1\n",
    "    }\n",
    "\n",
    "chinese_content = ['热门论文浏览量', #Page 1\n",
    "'中国特色社会主义制度优势和国家治理任务——由抗击\"新冠肺炎\"重大疫情引起的思考与建言13304', #Page 2\n",
    "'重大疫情治理中的中国制度优势11613',\n",
    "'从工程实际出发,结合鱼雷作战效能的动态性,综合考虑发射装置对鱼雷作战效能的影响,在鱼雷作战效能模型中引入发射装置的影响因素,同时对传统鱼雷寿命剖面进行了重新划分,首次把鱼雷在发射平台的装载阶段归入鱼雷的任务剖面,充分考虑鱼雷在整个寿命剖面内储存可靠性,装载可靠性和实航可靠性的时序性,则实航可靠性与储存可靠性,装载可靠性存在一定的关系,应用传统WSEIAC效能模型对鱼雷作战效能进行分析计算.我们已与文献出版商建立了直接购买合作。',\n",
    "'接购买合作' \n",
    "              ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Terms Lists\n",
    "\n",
    "term_list_1 = ['offer', 'sale', 'try'] #Offer language\n",
    "#{ }\n",
    "term_list_2 = ['guaranteed', 'best value', 'love'] #High-risk words\n",
    "term_list_3 = ['might'] #Exclusion\n",
    "term_list_4 = ['This is a disclaimer'] #Dislaimer\n",
    "term_list_5 = ['同', '建立', '与', '接购买合作', '门'] #Chinese characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define rules\n",
    "\n",
    "\n",
    "#Rule 1 finds high-risk phrases on a whole page with terms lists 1(in), 2(in), 3(exclusions)\n",
    "def rule_1(content):\n",
    "    y = find_terms_in(term_list_1, split_by_whole_page(content), terms_list_name = 'terms_list_1_in')\n",
    "    y = find_terms_in(term_list_2, y, terms_list_name = 'terms_list_2_in')\n",
    "    y = find_terms_notin(term_list_3, y, terms_list_name = 'terms_list_3_excluded')\n",
    "    y['rule'] = rule_names[rule_1.__name__]\n",
    "    return y\n",
    "\n",
    "#Rule 2 finds high-risk phrases in a sentence on a page.\n",
    "def rule_2(content):\n",
    "    y = find_terms_in(term_list_2, split_by_sentence(content), terms_list_name = 'high_risk_words')\n",
    "    y['rule'] = rule_names[rule_2.__name__]\n",
    "    return y\n",
    "\n",
    "#Rule 3 finds a missing disclaimer for an offer.\n",
    "def rule_3(content):\n",
    "    y = find_terms_in(term_list_1, split_by_whole_page(content), terms_list_name = 'terms_list_1_in')\n",
    "    y = find_terms_notin(term_list_4, y, terms_list_name = 'missing_disclaimer')\n",
    "    y['rule'] = rule_names[rule_3.__name__]\n",
    "    return y\n",
    "\n",
    "rule_names = {\n",
    "    rule_1.__name__: 'Rule 1: High-risk promotions on page',\n",
    "    rule_2.__name__: 'Rule 2: High-risk words in sentences',\n",
    "    rule_3.__name__: 'Rule 3: Missing disclaimers'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return only the triggered rows for one rule and one content set:\n",
    "def find_triggered_items(rule, content):\n",
    "    list_of_content = strip_url_from_content(content)\n",
    "    triggered = rule(content)\n",
    "    for col in triggered.columns.tolist()[2:]:\n",
    "        triggered = triggered[triggered[col] != \"\"]\n",
    "    df = pd.DataFrame(url_against_page_no(content))\n",
    "    triggered = pd.merge(triggered, df, on='page_number', how='left')\n",
    "    if triggered.empty == True:\n",
    "        return print('No phrases triggered for ' + rule_names[rule.__name__] + '.')\n",
    "    else:\n",
    "        return triggered.drop(['page_number'], axis = 1)\n",
    "   \n",
    "#Run multiple rules against some content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>terms_list_1_in</th>\n",
       "      <th>terms_list_2_in</th>\n",
       "      <th>rule</th>\n",
       "      <th>url</th>\n",
       "      <th>high_risk_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cake range #1. Come try our desserts. You're g...</td>\n",
       "      <td>try</td>\n",
       "      <td>guaranteed, love</td>\n",
       "      <td>Rule 1: High-risk promotions on page</td>\n",
       "      <td>url4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cake range #2. Come try our best value dessert...</td>\n",
       "      <td>try</td>\n",
       "      <td>guaranteed, best value, love</td>\n",
       "      <td>Rule 1: High-risk promotions on page</td>\n",
       "      <td>url5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While strawberry is out of stock, try raspberr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url3</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're guaranteed to love them</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url4</td>\n",
       "      <td>guaranteed, love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Come try our best value desserts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url5</td>\n",
       "      <td>best value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're guaranteed to love them.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url5</td>\n",
       "      <td>guaranteed, love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase terms_list_1_in  \\\n",
       "0  Cake range #1. Come try our desserts. You're g...             try   \n",
       "1  Cake range #2. Come try our best value dessert...             try   \n",
       "0  While strawberry is out of stock, try raspberr...             NaN   \n",
       "1                     You're guaranteed to love them             NaN   \n",
       "2                   Come try our best value desserts             NaN   \n",
       "3                    You're guaranteed to love them.             NaN   \n",
       "\n",
       "                terms_list_2_in                                  rule   url  \\\n",
       "0              guaranteed, love  Rule 1: High-risk promotions on page  url4   \n",
       "1  guaranteed, best value, love  Rule 1: High-risk promotions on page  url5   \n",
       "0                           NaN  Rule 2: High-risk words in sentences  url3   \n",
       "1                           NaN  Rule 2: High-risk words in sentences  url4   \n",
       "2                           NaN  Rule 2: High-risk words in sentences  url5   \n",
       "3                           NaN  Rule 2: High-risk words in sentences  url5   \n",
       "\n",
       "    high_risk_words  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "0              love  \n",
       "1  guaranteed, love  \n",
       "2        best value  \n",
       "3  guaranteed, love  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test 1\n",
    "\n",
    "risky_promotions_1 = find_triggered_items(rule_1, content_1)\n",
    "risky_promotions_1 = risky_promotions_1.drop('terms_list_3_excluded', axis = 1)\n",
    "risky_promotions_2 = find_triggered_items(rule_2, content_1)\n",
    "risky_promotions = pd.concat([risky_promotions_1, risky_promotions_2])\n",
    "risky_promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>high_risk_words</th>\n",
       "      <th>rule</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While strawberry is out of stock, try raspberr...</td>\n",
       "      <td>love</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're guaranteed to love them</td>\n",
       "      <td>guaranteed, love</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Come try our best value desserts</td>\n",
       "      <td>best value</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're guaranteed to love them.</td>\n",
       "      <td>guaranteed, love</td>\n",
       "      <td>Rule 2: High-risk words in sentences</td>\n",
       "      <td>url5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase   high_risk_words  \\\n",
       "0  While strawberry is out of stock, try raspberr...              love   \n",
       "1                     You're guaranteed to love them  guaranteed, love   \n",
       "2                   Come try our best value desserts        best value   \n",
       "3                    You're guaranteed to love them.  guaranteed, love   \n",
       "\n",
       "                                   rule   url  \n",
       "0  Rule 2: High-risk words in sentences  url3  \n",
       "1  Rule 2: High-risk words in sentences  url4  \n",
       "2  Rule 2: High-risk words in sentences  url5  \n",
       "3  Rule 2: High-risk words in sentences  url5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test 2\n",
    "\n",
    "all_high_risk_phrases = find_triggered_items(rule_2, content_1)\n",
    "all_high_risk_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>terms_list_1_in</th>\n",
       "      <th>missing_disclaimer</th>\n",
       "      <th>rule</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banana ice cream sale.</td>\n",
       "      <td>sale</td>\n",
       "      <td>This is a disclaimer</td>\n",
       "      <td>Rule 3: Missing disclaimers</td>\n",
       "      <td>url1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cake range #2. Come try our best value dessert...</td>\n",
       "      <td>try</td>\n",
       "      <td>This is a disclaimer</td>\n",
       "      <td>Rule 3: Missing disclaimers</td>\n",
       "      <td>url5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase terms_list_1_in  \\\n",
       "0                             banana ice cream sale.            sale   \n",
       "1  Cake range #2. Come try our best value dessert...             try   \n",
       "\n",
       "     missing_disclaimer                         rule   url  \n",
       "0  This is a disclaimer  Rule 3: Missing disclaimers  url1  \n",
       "1  This is a disclaimer  Rule 3: Missing disclaimers  url5  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test 3\n",
    "\n",
    "missing_disclaimers = find_triggered_items(rule_3, content_1)\n",
    "missing_disclaimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No phrases triggered for Rule 2: High-risk words in sentences.\n"
     ]
    }
   ],
   "source": [
    "#Test 4\n",
    "\n",
    "find_triggered_items(rule_2, content_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proximity - in page, in sentence\n",
    "#run multiple rules against some content"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Limitations:\n",
    "Case sensitive\n",
    "Requirements need to be well-defined by the client (e.g. find this very specific thing). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
